{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ec9ad9-bc6e-434c-9c22-eba0ca114883",
   "metadata": {},
   "source": [
    "# 1. Feature Engineering Objective.\n",
    "\n",
    "The objective of feature engineering in this project is to transform raw loan applicant data into a **consistent, numerical, and model-ready format** while preserving the underlying information relevant to **loan default risk**. Since the dataset contains a mix of numerical and categorical variables, appropriate preprocessing is required to ensure that all models can effectively learn from the data.\n",
    "\n",
    "Feature engineering will be performed with the following principles in mind:\n",
    "\n",
    "- **Identifier columns** (such as unique loan IDs) will be excluded, as they do not carry predictive information.\n",
    "- **Numerical and categorical features** will be handled using suitable transformations to ensure compatibility with machine learning algorithms.\n",
    "- **Data leakage will be strictly avoided** by learning all preprocessing steps exclusively from the training data.\n",
    "- **A consistent engineered feature set** will be used across all models to enable fair and meaningful comparison between algorithms.\n",
    "- The **feature engineering pipeline will be reproducible and deployment-ready**, allowing the trained model to be reliably applied to unseen data.\n",
    "\n",
    "This approach ensures that the engineered features support **robust model training**, **reliable evaluation**, and **future deployment** without introducing bias or inconsistencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb908e-7e19-4b1a-ae45-56bf12283c40",
   "metadata": {},
   "source": [
    "# 2. Train–Test Split Strategy\n",
    "\n",
    "The dataset is split into training and test sets **before any preprocessing or feature transformations** (such as encoding or scaling) to prevent data leakage and ensure a fair evaluation of model performance.\n",
    "\n",
    "- The **target variable (`y`)** is defined as the `Default` column, which indicates whether a loan default occurred.\n",
    "- The **feature matrix (`X`)** consists of all remaining columns excluding:\n",
    "  - the target variable (`Default`)\n",
    "  - the unique identifier column (`LoanID`)\n",
    "\n",
    "The `LoanID` column is removed because it serves only as a record identifier and does not contain predictive information.\n",
    "\n",
    "Due to the observed **class imbalance** in the target variable, a **stratified split** is used to preserve the proportion of defaulters and non-defaulters in both the training and test sets.\n",
    "\n",
    "- The data is divided into **80% training data** and **20% test data**, providing sufficient data for model training while retaining an unseen test set for final evaluation.\n",
    "- A **fixed random state** is used during the split to ensure reproducibility of results.\n",
    "\n",
    "Model selection and hyperparameter tuning will be performed using **cross-validation on the training set** only.\n",
    "\n",
    "The **test set will be used exactly once**, after model selection is complete, to evaluate the final model’s performance and provide an unbiased estimate of generalization ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca404f14-3ce8-4534-9006-e585c6e8f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d37acc-c4ea-46d8-8356-206a0fbdeefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Loan_default.csv\")\n",
    "df.columns = df.columns.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853c3c33-f170-4ba3-b839-2504d5ea10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"default\"]\n",
    "X = df.drop([\"default\", \"loanid\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0292431-a71a-4944-9ea0-1e41e7f7cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3eb45f-4515-4149-b197-b7340befe593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (204277, 16)\n",
      "df_test shape: (51070, 16)\n",
      "y_train shape: (204277,)\n",
      "y_test shape: (51070,)\n"
     ]
    }
   ],
   "source": [
    "# Verify shapes\n",
    "print(f\"df_train shape: {df_train.shape}\")\n",
    "print(f\"df_test shape: {df_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d0b21-3d1d-484d-b616-a9fa09a1c7ca",
   "metadata": {},
   "source": [
    "# 3. Handling Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c8ce0-cfde-481d-86b3-2b886ed837b7",
   "metadata": {},
   "source": [
    "Several features in the dataset are categorical in nature and must be converted into numerical representations before being used by machine learning models.\n",
    "\n",
    "The categorical features identified in this dataset are:\n",
    "\n",
    "- **Education**\n",
    "- **EmploymentType**\n",
    "- **MaritalStatus**\n",
    "- **HasMortgage**\n",
    "- **HasDependents**\n",
    "- **LoanPurpose**\n",
    "- **HasCoSigner**\n",
    "\n",
    "These features are **nominal**, meaning there is no inherent ordering between their categories (e.g., *Married* is not greater than *Single*).\n",
    "\n",
    "**One-Hot Encoding** is chosen as the encoding strategy because:\n",
    "\n",
    "- It avoids introducing artificial ordinal relationships between categories.\n",
    "- It is compatible with a wide range of models, including:\n",
    "  - Linear models\n",
    "  - Tree-based models\n",
    "  - Gradient boosting models\n",
    "  - Neural networks\n",
    "\n",
    "To prevent **data leakage**, the encoding process will be **fitted only on the training data** and then applied to the test data.\n",
    "\n",
    "The encoder will be configured to **handle unseen categories gracefully**, ensuring robustness during model evaluation and reliable behavior during future inference and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "751a51a6-a5b1-4abc-be3a-2f536ea365e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_cat shape: (204277, 22)\n",
      "X_test_cat shape: (51070, 22)\n",
      "Number of encoded categorical features: 22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = ['education', 'employmenttype', 'maritalstatus',\n",
    "       'hasmortgage', 'hasdependents', 'loanpurpose', 'hascosigner']\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown='ignore',sparse_output=False)\n",
    "\n",
    "categorical_transformer = ColumnTransformer(\n",
    "    transformers=[('cat',categorical_encoder,categorical_features)]\n",
    "    ,\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit on training data and transform both train and test sets\n",
    "X_train_cat = categorical_transformer.fit_transform(df_train)\n",
    "X_test_cat = categorical_transformer.transform(df_test)\n",
    "\n",
    "# Retrieve encoded categorical feature names\n",
    "cat_feature_names = categorical_transformer.get_feature_names_out()\n",
    "\n",
    "# Sanity checks\n",
    "print(\"X_train_cat shape:\", X_train_cat.shape)\n",
    "print(\"X_test_cat shape:\", X_test_cat.shape)\n",
    "print(\"Number of encoded categorical features:\", len(cat_feature_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5aa23a-96f9-479a-a15f-f34eac2045e0",
   "metadata": {},
   "source": [
    "# 4. Handling Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfa72c-6ac8-4a4b-bc6e-f136bc5d3ef7",
   "metadata": {},
   "source": [
    "The dataset includes several numerical features that capture quantitative information about the applicant’s financial profile and loan characteristics.\n",
    "\n",
    "The numerical features considered in this project are:\n",
    "\n",
    "- **Age**\n",
    "- **Income**\n",
    "- **LoanAmount**\n",
    "- **CreditScore**\n",
    "- **MonthsEmployed**\n",
    "- **NumCreditLines**\n",
    "- **InterestRate**\n",
    "- **LoanTerm**\n",
    "- **DTIRatio**\n",
    "\n",
    "These numerical features exist on very different scales (for example, *Income* versus *InterestRate*), which can negatively impact certain machine learning models if left unprocessed.\n",
    "\n",
    "Models such as **Logistic Regression** and **Neural Networks** are sensitive to feature scale and typically perform better when numerical inputs are standardized.\n",
    "\n",
    "**Tree-based models** (Decision Trees, Random Forests, XGBoost) are generally scale-invariant; however, scaled numerical features are still prepared to maintain a **consistent and reusable preprocessing pipeline** across all models.\n",
    "\n",
    "The **Age** feature is treated as a continuous numerical variable and is included in numerical scaling. No age binning or discretization is applied at this stage to avoid unnecessary information loss.\n",
    "\n",
    "**Standardization** is chosen as the numerical preprocessing method, as it centers features around zero and scales them to unit variance.\n",
    "\n",
    "To prevent **data leakage**, the scaler will be **fitted only on the training data** and then applied to the test data using the learned parameters.\n",
    "\n",
    "Numerical preprocessing is handled **separately from categorical encoding** to maintain a clear separation of responsibilities and to allow flexibility for future feature experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0779ca-6514-4e9b-89ec-0fa51d4ccf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_features = ['age', 'income', 'loanamount', 'creditscore',\n",
    "       'monthsemployed', 'numcreditlines', 'interestrate', 'loanterm',\n",
    "       'dtiratio']\n",
    "\n",
    "numerical_transformer = ColumnTransformer(\n",
    "    transformers=[('num',StandardScaler(),numerical_features)]\n",
    "    ,\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X_train_num = numerical_transformer.fit_transform(df_train)\n",
    "X_test_num = numerical_transformer.transform(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50064e0-f32f-4c86-b147-e020b35e4f49",
   "metadata": {},
   "source": [
    "# 5.Feature Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae2545-ebf2-4046-babf-df890d587a24",
   "metadata": {},
   "source": [
    "- After preprocessing, the dataset consists of two separate feature representations:\n",
    "  - One-hot encoded categorical features generated in **Section 3**\n",
    "  - Scaled numerical features generated in **Section 4**\n",
    "\n",
    "- These two feature sets are combined **column-wise** to form a single, unified feature matrix for modeling.\n",
    "\n",
    "- Column-wise concatenation ensures that:\n",
    "  - Each row still represents the same loan applicant\n",
    "  - Feature alignment across samples is preserved\n",
    "  - No mismatch occurs between numerical and categorical features\n",
    "\n",
    "- The same feature assembly procedure is applied **consistently** to both the training and test datasets.\n",
    "\n",
    "- No additional fitting, scaling, or encoding is performed at this stage; only **previously transformed features** are combined.\n",
    "\n",
    "- The outputs of this step are:\n",
    "  - **X_train_final**: Final feature matrix used for model training and cross-validation\n",
    "  - **X_test_final**: Final feature matrix reserved for final model evaluation\n",
    "\n",
    "- The resulting feature matrices are fully numerical and compatible with all planned models, including:\n",
    "  - Linear models\n",
    "  - Tree-based models\n",
    "  - Neural networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad034ed-1f83-4d7a-935f-008cbe8a7a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204277, 31)\n",
      "(51070, 31)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((X_train_num, X_train_cat), axis=1)\n",
    "X_test = np.concatenate((X_test_num, X_test_cat), axis=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
